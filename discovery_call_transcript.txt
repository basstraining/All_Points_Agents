[0:03] Emmit Hood: How you doing?
[0:05] Michael Kalinowski: Not too bad. You guys out in Cali?
[0:09] Emmit Hood: San Fran, yep. Out here in San Fran. How about yourself?
[0:13] Michael Kalinowski: We're in Atlanta. Everybody on the All Points team is in Atlanta right now.
[0:19] Nathan Bass: How's the weather? Pretty chilly, I'm hearing.
[0:24] Michael Kalinowski: It's actually chilly today, but yesterday was like 65 and sunny, which is pretty cool.
[0:30] Emmit Hood: You guys had a big snowstorm recently, no?
[0:33] Michael Kalinowski: Yeah, we did. Well, we were supposed to have had one. It was kind of sporadic throughout the southeast. And I was literally just on a call with a buddy from Louisville before I hopped on this call. And we got like a little bit of ice and nothing too concerning. And he's in Louisville and said, you know, we had like 10 feet or 10 inches of snow and an inch of ice and it just melted. Like it jumped to 70 degrees on Saturday and now there's water everywhere. So. we got pretty lucky but uh i guess some people in the southeast did not get so lucky i know nashville got hit hard too um so uh uh oliver and adam just jumped on as well and adam is uh taking the first part of the call he's he's driving uh somewhere and
[1:20] Adam Zawacki: so he's just gonna be just just listening in for the first 10 minutes um but yeah i'm stuck in traffic right now so it might be 20 minutes welcome to atlanta
[1:32] Michael Kalinowski: And I don't think Paul's probably not on, right? Paul's out right now. But this is the core of kind of the IT and systems team at All Points. So we met with Ben. Ben was staying with me a couple of weeks ago, and we were just kind of going through Arcade and what you guys do. And I showed him some of the very mundane systems that we use. Almost everybody in our industry uses, which is a pretty big industry. And he said there's a seems like there could be a strong use case. So I don't know what all he shared with you, but that's we I sent him a list of our systems and what they do. And I don't know if he was able to make heads or tails of that. But I figured I would I figured, you know, maybe it'd be helpful to to hear. Maybe have you guys kind of walk through what the system does, because Ben showed me, but he did not show Oliver. um so i'll let you guys take the meeting however you want and and you know tell us where we can fill in details but um yeah whatever we can do to make this valuable for you guys would be just let us know cool cool cool cool oh ben gave me a little bit of context um he
[2:50] Nathan Bass: was able to send over the doc so emin and i took a took a look at it i'm not super familiar with the third party logistics space but through the wonderful world of AI. I was able to get a little bit more context there, but I'd love to just get a walkthrough of All Points. As a business generally, we can start with intros first. I'm Nathan Bass, I'm GTM associate over here at Arcade, kind of a generalist on the go-to-market side.
[3:23] Emmit Hood: I'm very similar to him, we're both kind of...
[3:27] Oliver Schouest: do a little bit of everything i'm the gtm engineer over here so yeah i'm oliver i work with adam and it i kind of i've touched a little bit of everything uh i'd love to know a little bit more about like what y'all do and like how you compare to like some other mcp services and you know all that like yeah cool yeah we can definitely get into that uh in a bit
[3:57] Michael Kalinowski: I'll do an intro. Michael. I'm mostly in charge of sales and marketing and a little bit of operations. I mean, we're not a huge company. We're like 30, maybe 35 front office employees. But obviously we're in the warehousing business. So we've got probably close to 100 employees if you factor in the warehouse employees. But yeah, I'm just. As a small company, we all wear many hats, which is probably what you'll gather from this conversation. And then Adam, I don't know if he wants to do an intro. He's on mute. Yeah,
[4:36] Adam Zawacki: I'm Adam Zawacki. I'm the director of IT. So I've been with All Points
[4:42] Oliver Schouest: 20-something years.
[4:45] Adam Zawacki: So, yeah, I know our systems inside and out. I'm interested to see where this could fit in and how it could help us. I don't I didn't look at the document that they sent over Did you guys like? Let them know that we're switching WMSs because that will radically change it. Our WMS is like our core software. You know, that's what runs our whole thing. So the fact that it's switching, you know, might change what they're thinking about.
[5:19] Oliver Schouest: The doc that I made was a quick and dirty, but it had like most of the systems and like, I guess, names and a brief description. I used Gen A to fill in a lot of it. Then I kind of went through it and made sure. It's mostly accurate, but I mean, it's pretty brief. So we definitely have to expand on it.
[5:36] Nathan Bass: Cool. Now, very helpful. Very helpful for us. I think I'd love to start with a higher view of the business of All Points. So you guys offer five services I saw on your site. We'd love to get a better understanding of what the biggest revenue driver is. Yeah, just understand that.
[5:57] Michael Kalinowski: I can give you the elevator pitch on All Points. So. We are a third-party logistics company, right? So, you know, there's some clues there. We do logistics, but we are a third party. So we do logistics services for other customers. We have warehouses, too, in Atlanta, which are our only two locations. And let's say you order a phone case. Well, if we work with this phone case company, we can warehouse all of their phone cases. and then and we integrate with their Shopify store or whatever shopping cart they're on. And when they get an order, our team walks to the shelf, scans the barcode, takes the phone case, puts it in a box, tapes the box shut, puts a shipping label on it and ships out the door. That is the most simplified version of what we do. There's some nuance because clients are different and they have different needs, but at its core, we take. we work with companies we take all their products in we store them and then we ship them out to their customers as we receive orders and that's that's we call that pick and pack so you go to the shelf you pick an item you pack it and then you ship it out that is our main source of revenue so we we um we work with a lot of e-commerce brands so um And like Turtle Box, we do a lot of Turtle Box speakers and stuff of that nature. So consumer goods, apparel, we basically what in the proposition here and why we're in business and why there's a ton of people in the 3PL businesses. Do you really want to go out as a brand and lease a warehouse and then put racking in and put systems in? buy WMS and pay for it every month and then be responsible for hiring people to pick and pack orders and coordinate with carriers and do all that stuff or would you rather just look you market the product you sell it we'll handle everything else so that's that's kind of our core function that that we do which is warehousing and distributing customers goods moving moving products from one end of the warehouse to the other and ultimately getting into the customer store stuff so Where can I maybe fill in some gaps there on that? That's at a high level.
[8:23] Adam Zawacki: Yeah, and the one thing I would add to that is he focused on D2C, which is obviously direct-to-consumer orders, but we also do big-box retailers and handling their entire supply chain from that point. Like, hey, we're going to sell these on Amazon. We're going to sell them to Target, and we would handle that.
[8:45] Michael Kalinowski: right we're kind of like where they would store it and we would ship it to whether to a distributor or to an end customer yeah yeah yeah because there's an entirely separate process for shipping a phone case to your doorstep and shipping 50 000 phone cases to every best buy in america we do both facilitate both but that process is very different so yeah good point adam And so, okay, let's take that down in terms of systems and technology. We operate off of pretty much three main systems. Veracore, which is our WMS, which is the brain. It integrates with the customer Shopify, directs orders. It runs everything. It runs 90% of the operations in our warehouse. Then we use QuickBooks for billing. And then we use a system called TACT. which is labor management, which basically TACT, T-A-K-T, integrates with our WMS and just is keeping track of the labor hours that people are doing so that we understand our cost centers and how we're generating revenue. Is it profitable? Is it not? But the biggest system is the WMS, and that's where we spend most of our time, and that's where the customer service team spends most of their time. Hey, your inventory was short. when you guys received this new product and why we were supposed to have received a thousand phone cases, we received 990. Why is that? Okay, well, let's go in and see if we can figure it out. So the WMS is the core. I mean, that's where...
[10:28] Adam Zawacki: everybody company spend much their time and that and that's the software that we're changing over the next several months we're in the infancy stages of it now but we'll be switching from Veracore to DePasco there's
[10:43] Michael Kalinowski: a much more enterprise WMS so questions on All Points Veracore DePasco TAC I guess
[10:57] Nathan Bass: so you described like the b2b motion the b2c side of it where is the biggest like bottleneck like i imagine that unlike b2c if like a small inefficiency that's like going to balloon right because you have more people that you need to distribute to or is it more on the b2b side uh we just love to walk through like where the friction or the inefficiencies are sort of living so so okay go ahead i was gonna say it lies in both right
[11:27] Adam Zawacki: So the D to C is generally more straightforward because it's all walking around the warehouse, picking orders, you know, packing them and shipping them. It's not too complicated where we can, you know, gain some efficiencies where we're grouping like orders together, batch processing stuff. So instead of me picking one order at a time, I'm going to pick a thousand orders that are exactly the same and back. ship them all together um that's where the efficiencies are gained but the b2b can get really complicated because it's hardware the pounds can only be 40 inches time you need to put all the labels on the left hand corner but uh nordstrom's is the exact opposite they want 46 inch high pallets and you know so it gets more complicated so while the orders there's less orders they're more complicated with more stuff on them so you know that to me that's probably more of a bottleneck um but we do obviously way more uh direct to consumer orders okay cool um and then maybe uh
[12:41] Michael Kalinowski: for some additional contacts too like bottlenecks on our end or We have account executives and they handle the relationship with the clients directly. And that's where you'll see, you know, an inbox every single day full of really menial requests like, hey, where did you know, did this order ship? If so, what is the tracking number? You know, and then the person is to go into the WMS and type it in and track it down or, hey, has this truck delivered yet? Well, you know, there's a tracking number, just go check the tracking number. But we would have to go in and click on the tracking number and say, no, it hasn't delivered yet. It's, you know, still looks like it's still in Augusta or still in Savannah, Georgia. A lot of what our AEs do is simple tasks, but tedious tasks. So go in and extrapolate data and, you know, give answers that can only. The answers can only be found by going through the system and going through and getting answers that are plain text answers, I guess, which is probably relevant to you guys, because that's where some of the agentic stuff that Ben had showed us was like, it'd be so much nicer to just prompt somebody to do this or have an agent running in the background that has a log of all tracking all of our truck shipments. And, you know, if one is delayed, let us know that one is delayed and email the customer that's delayed or as the truck gets delivered. email the customer and say hey this has been delivered you know want to confirm on your end that you've received this so um that's i think where uh there's probably is there's probably some solutions from your guys end but uh honestly everything that we do and all the systems we have is is pretty simple data to understand and digest especially for ai or an llm and what you guys the terminology you guys use but um Yeah, that's kind of what we do. Like, if you think about it, there's only so many ways you can bring a box in and ship it out the door. But when you're doing 10,000 or 20,000 or 30,000 of them a month, you're going to have questions and concerns. And you're going to have a customer service responsibility to the customer, to the client. So that's and this is this is like universal across. supply chain and logistics, everything. It's such a, a laborious, tedious business. Um, not because it's complex, but just because when you've got.
[15:26] Adam Zawacki: thousands and thousands of things moving every day you have to across across 100 clients you have there's a lot of organization i guess that's what i'm trying to say so and does that and i would say to add to that and across you know 100 vendors right because we're dealing with ups once it gets out of our system or usps or um the trucking companies so there's like that level of yeah we're sending out those thousand packages but now now there's other people involved it's not just us in turtle box it's us and however we're shipping it right along the turn kind of going off of what michael was saying about like i guess the way i don't i want to learn more from you all about what exactly your integrations
[16:14] Oliver Schouest: and you know automations excel at but i guess from like i don't know i played around with cloudbot or whatever you want to call it i could see it being super helpful so I think of the document that I made the systems, I mentioned a system called Front. That's like, we kind of steered away from it. But that the whole point of that system was to try to like, streamline communication between like the AEs and accountability. So something that like, we've got a lot of these email groups for different clients, something that would, you know, I guess, track actionable items, you know, that type of thing. And of course, I don't know how complicated you can make it. There's API. points for our WMS. It could possibly query up the report or whatever and have it so you click a button to approve and send the answer or whatever. I don't know. That's how I can see it being super helpful.
[17:03] Nathan Bass: Cool. Well, I think it was a good segue. I don't want to spend too much time in the deck, but show you a slide quickly just to give you a view. So Arcade sort of sits in between the large language models and these other MCP clients and the agent building frameworks. And we sit in between as like what we call an MCP runtime. So it's just this governance layer where you're able to have visibility into what systems are being called. Right. So similar to like an API endpoint, when you're calling it in like Python script, you're going to be have to specify exactly what you want to be calling. Now, what Arcade does is it lets the LLM decide what tools that you've connected. Right. So you're going to scope the exact. permissions, the systems that you want to hook up to an MCP gateway. So we're the MCP gateway provider and let the LLM communicate with your enterprise systems. So whether that's WMS and you want to query that, whether it's Gmail or whatever email client you have, being able to go into it and just with normal language, being able to say, I want to see all of the shipments to this vendor. over the past week right so there's a ton of directions you can go we're sort of that like the gateway we're the security guard that's allowing information to move back and forth so another question i have so i've played around a little bit i'm trying to i've been working on it the last couple weeks we're switching over to this new wms and i've scraped all the knowledge base and stuff and i made like a rag retrieval thing with
[18:46] Oliver Schouest: all this ai stuff i think your whole view off is that basically what it is like it
[18:51] Nathan Bass: your environmental variables all that lives with you guys and it's one place one place to change it i think that's super yeah i mean that's huge yep and then we have something called just in time off where as you're running the agent you'll get prompted to authorize it so as it's needed you will be able to off uh so it's pretty clean i mean i've been using it and i have been using it for like gtm stuff there's a ton of directions you can go with it it could absolutely help on like the AEs with customer communication stuff. It could help with some like the back-end inventory management stuff. So it definitely sounds like there could be a fit. I'll pause there for any questions.
[19:40] Michael Kalinowski: I don't know. I'm not technologically inclined, so I'm not going to have very educated questions on this.
[19:46] Oliver Schouest: I mean, so basically you guys are just like an MCP router type of thing, right? At its core. So we could, I mean, if we wanted to run local models and own our data, you know, we could do that. Can we run, can we spin you guys as this like thing up in a doctor container? How is it hosted and all that? What are our options?
[20:06] Nathan Bass: I'll let Emmett, because I'm also not the most technically inclined. Emmett, if you want to take that.
[20:12] Emmit Hood: Yeah, for sure. So we have our normal SaaS offering, which. you know runs in the cloud just arcade.dev but we also have a on-prem offering as well for our enterprise customers so um we're a model we're cloud agnostic and we're also able to be deployed directly in your environment as well
[20:33] Michael Kalinowski: So I guess some of the things that we were thinking about with this, and I don't know, I guess maybe it's a good use of the system, maybe it's not, but like if we wanted to say, you know, prompt it and like for financial modeling and say, you know, generate, you know, a revenue report using tact and, and our WMS and like, you know, Give me a report on TurtleBox and what was the profitability? Where were we bleeding money? Where were we spending the most time? It should have all of that data. It can go together with that and create an output.
[21:10] Nathan Bass: Yeah, exactly. And then you could take that output, make a Google Doc with it, send it to people on your team that you want, right? You can take it end-to-end. So in addition to actually clearing the data in your software that you're using, you can also take it to the full distribution through the channels you want.
[21:33] Michael Kalinowski: So how does the training work? Do you guys, do we have to? So two things I want to know more about. How does the training work? And then maybe after that, talk about some of the agentic capabilities and what that would look like, could look like.
[21:49] Nathan Bass: What do you mean by training?
[21:51] Michael Kalinowski: So Ben was saying one of the things you have to do is train. the train the LLMs on your system and your, maybe your terminology or, you know, how you guys operate so that it can go through and actually pull relevant data. Or when you give it a simple prompt, it can take it and do something effective with it as opposed to just, you know, sitting there and spinning and saying, I don't know what you're referencing.
[22:22] Oliver Schouest: I guess a better question is, are you guys only the. do you guys only build and service like the MCPs or will you like white glove the whole data database building the structure all that so the queries you know work and are efficient and then I guess another question not related to that how does the context work when using your MCP tool and like calling tools through that does that live in its like own little sub-agent or is that the same as like installing tools and MCP service directly with that documentation that makes sense
[22:55] Nathan Bass: That it makes sense. It makes sense. I don't know the answer to that off the top of my head. I'll start with like the training side. I think like when you're talking about like relationships within your system, you can establish those through like a markdown file or like a skill like you. You can basically write out what those relationships are once and then it will be used as that context for the agent to go go into it and say, OK. And like, I know that. you know this object is related to this object and when i'm interested in this thing it will be able to go and query the exact information you want so it might take a little bit of establishing those relationships on the front end but then as it goes on it'll know that right so that's where like your internal knowledge you can put that into writing into like an internal knowledge base and then it'll use that as the context to help help it run um
[23:51] Oliver Schouest: and then i guess another question do you guys i guess for like some of these skills and stuff you're not relying on llms right you're building python scripts and stuff and building out toolkits for the lms to query so it has you know like it's not you know generating results i guess it's the best way to could you could you clarify that that question sorry for example like once we you know set up all the environmental variables and the workflows like these reports don't if you know you want your reporter bot to work well How does that work? I guess, do you does the LLM generate the Python script to run those queries and stuff at that moment? Or do you have to like configure, you know, base queries and like give it examples and all that? And whose response? Do you guys set up all that type of, I guess, setup?
[24:49] Nathan Bass: I think that the LLM will will create that as needed, depending on the use case. And Emmett, correct me if I'm wrong, but like, you know, an example that I've been using where I've been making like an HTML file, it created a Python script to generate that HTML file based on information that I was feeding it because that's what it needed to do. So it did it at the time of needing to create it. I'm not sure if that's what you're getting at.
[25:19] Oliver Schouest: I guess in my experience, like I've played around with Cloudbot and Cloud Code and all this. Once you add over a certain amount of tools, it just gets kind of bloated. model gets lazy and unless you're like unless you kind of like know the syntax of your tools and like directly call them like kind of you know tell it use this tool this tool this tool i don't know it it doesn't seem to work as well or if you don't have like python scripts to do like the the parts that like you can't just generate right you don't want to assume the table headers that type of thing
[25:53] Emmit Hood: So we've actually released a, that's a great point. That's a huge issue with MCP. And so what we've done at Arcade is we recently, just I think yesterday, released our spec for building agent optimized tools. So what we do when we build these toolkits, for example, with I think Deposco is the name of your new WMS, we could go in and kind of, you know, what are three or four workflows or examples of things that you would need your LLM to do? in that system and we could actually expose the instructions directly to the LLM through the tool itself. So the TLDR is the the LLM will see instructions on how to use the tools and when to use those tools which is a great way to reduce that bloat. We also have a proprietary and then the next week or two we're releasing our MCP tool search. So instead of jamming the context window with hundreds of tools it'll only it'll only show like the the fibers like a sub-agent that pulls end of the Exactly, exactly. So it's a good way to manage that context flow. And that's also something that's releasing in the coming days directly through our platform. So not sure if that answered the question. But yeah, more context is in that link I sent with kind of how we administer these tool patterns.
[27:05] Oliver Schouest: And then I guess the second part of my question is how like a white glove is this for the other parts? You know what I mean? Like, if you want your database, you know, reporting agent to work right you have to have the database structured the best practices and all that you know or or i guess you know the whole example of the ae asking to run reports unless they're like very specific with the name of the report and it's a default report template like so that's the problem i've run into when i'm trying to build something because i've tried to build something like this for one of our clients just quarter four you know data that's a great point and
[27:45] Emmit Hood: And so I think a lot of that comes down to using well-defined tools. So I think a great example in my life is I recently just I think yesterday or maybe it was Wednesday, had to spin up a report for our sales team to kind of capture our GTM, our pipeline data and share it with the company. So what I did was I didn't actually open any of our systems or any of our databases. I just used AI to help query. And because it had the right tools that said. here is the schema of our database, here is where this data lives, and I, you know, defined, here's what I want the report to share, here's the data you need to find for me. It was able to kind of, you know, traverse the database really intelligently. So I think a lot of that just comes down to these models getting exponentially better week over week, month over month. And I think we have kind of crossed that threshold where the models are able to, again, with a well-defined toolkit, traverse a complex database and write the right queries because the tools,
[28:41] Oliver Schouest: that it needs to use are right in front of it if that answers your question okay and then i guess aside from the toolkit do you guys tune the models at all or are you guys just using the base base models giving them the tools i guess you're not um what do you call it like adding in you know yeah new chunks and all that you know what i mean no we we only work through the um
[29:10] Emmit Hood: the tool layer itself, meaning like the MCP servers, the tools, all that stuff. That's where we kind of come into the stack.
[29:26] Adam Zawacki: Cool. Well,
[29:26] Nathan Bass: I know we're out of time. Emmett, do you want to go through a quick demo? We can maybe set up some time next week. I'll send over some information.
[29:39] Emmit Hood: and you guys can take a look at it and maybe like okay cool yeah i think this would be a great segue into kind of showing some of that the model's intelligence kind of at work so what i love to do now is just kind of i'll go ahead and read the prompt and then kind of let you guys uh i'll kind of show the kind of explain what's happening under the hood so let's start a new chat here i'm just going to ask claude having a great conversation with the All Points team We want to schedule a follow-up for some time next week for 30 minutes. do me a favor and find three time slots on my calendar and everyone on the Arcade Team's calendar that works that we're all available and go ahead and write a follow-up email thanking them for their time and looking to schedule one of those three time slots. So just For a bit more context here, I'll go ahead and share what this looks like under the hood, but I have my gateway connected. So it's connected to my Gmail and to my calendar, which is all the agent needs. This is not a very robust prompt. It's not a great prompt, but the agent will be able to figure out kind of how to translate my intent into a series of actions here. So this is our URL elicitation, meaning our just-in-time off, and this is so I just have to go here. and quickly go through arcade and then authorize my agent access to use my calendar so let me go ahead and do that right now is this the one time thing you're doing here or every time that
[31:17] Oliver Schouest: it wants to that's kind of just my question on how y'all handle the uoff and like the environmental variables is you know whenever you update the docker container or whatever stuff I'm using. It's like you have to reauthorize everything unless you're using like a U auth key or whatever.
[31:33] Emmit Hood: I might need, I think that would be a good question to pass. That's a great question. I'll pass it on to our solutions engineer. He could provide more context there on the token refresh and how we handle that. So now that I've authorized access to my calendar, again, this was not a great prompt, not very proud of it, but the agent was able to find the thread in my Gmail. And is checking availability?
[32:03] Oliver Schouest: And I guess another question, are you guys benchmarking the different models and how they work? Because something like this where it has email and calendar and organization-wide access, I'd probably want to keep on a local model. I mean, I've got a 5090 at home, and it runs smaller models well. Do you guys like I don't know, like, would you be able to give us direction on like which workflows would be able to run local models versus cloud models? Maybe some of that, like the segmenting of sensitive data and stuff.
[32:38] Emmit Hood: That's a that's a great point. I think I might need Guru to provide more context on what he's seen work. I generally find that for most workflows, you know, the bigger the model, the better. That said, for small use cases like, hey, send an email or, hey, quickly check our database, generally a smaller model will be able to do just fine. And just, I'm not sure, I think I saw you guys use, can you remind me one more time what models you're running locally?
[33:08] Oliver Schouest: We've got a whole, no, I'm not running any, like, for the company. Like, only I'm doing it for, you know, to help me out with understanding the company better, I guess. But I'm using just Olamo models, like, I think Gwen likes with a dolphin. the coder models. But I use cloud code mainly for 90% of the cloud stuff.
[33:30] Emmit Hood: I generally find that Opus or GPT-353, whichever of the two you prefer, has the best tool accuracy. I think I'll definitely ask Guru to provide more context on that as well. But that's a great question. And real quick to close the loop on this demo before I show what happened. So if you remember, I prompt said. send the email or write the email to these folks. I'll go ahead and show my Gmail drafts in a second here. But this is an important part of Arcade where you can really govern what tools the agent can access. So if you were to roll this out to a lot of your, you know, not workers, a lot of your employees, you might not want their agents just firing off emails. We're human in the loop step to verify that these things are actually accurate. So I've intentionally removed the send email, the send draft email, or any of the delete commands from this gateway. So the model is unable to do these things, even if I tell it to do it. So now if we go check quickly one more time, check that. Yeah, so it's created the draft in my Gmail. And we can go ahead and verify that right now. The draft was created with, let's see. Yeah, so this at 10.03, just a couple minutes ago. Here's our follow-up email that I'll go ahead and send after the call. So that's just a quick run-through of how this looks in action.
[34:51] Oliver Schouest: and how arcade kind of governs the actual tools themselves here's a silly question do you guys integrate with uh we're an outlook microsoft company uh just looking at like you know ai tools and similar things like i don't know notion or whatever stuff like that you know they usually either work with google stuff or microsoft and very few work with both of you guys yeah
[35:19] Emmit Hood: We offer over 8,000 tools out of the box and we're adding more every day. You can also bring your own MCP servers as well and expose them through Arcade's gateway. So we integrate with pretty much any. Anything in your tech stack will integrate with it. And if you don't have an integration, we could definitely build a toolkit for that as well.
[35:40] Oliver Schouest: And I guess when you help out a company like us, how do you determine what workflows to build out first? Is there so many ways you could build MCP service to help us? Where do you start? How does that look? Yeah,
[35:57] Nathan Bass: I think. from my perspective, it's where's the most loss, right? What's the lowest hanging fruit? We talked about what AI is best at, those repetitive, tedious tasks. What do you feel on your side could be the first thing to knock out, right? And then going from there. So I think it really depends on your business and your needs, because you guys are going to have the best understanding of what that looks like. But given we're agnostic in so many directions. we can help with whatever that looks like.
[36:36] Oliver Schouest: And then I saw in the demo, like you had to turn on the MCP gateways that you wanted to use and all that. That seems a little advanced for like 99% of our users at this company. Do you guys, do you have plans to make some sort of like, what do you call it? Whatever CloudBot's called, like that type of like overhead agent routing.
[36:59] Emmit Hood: to where you can kind of just ask it what you want and it'll you know run your prompt through a prompt agent that asks you you know all that stuff yeah so the the control plane i shared would mainly be for your it users so that the folks who are governing you know let's say you have a marketing department and you only want them accessing these tools so that would be you guys would go ahead and set up that gateway and all you have to do is a cloud user all of your users would just simply go into cloud and select the connector they would just press the toggle that you guys have provided for them and just to give them that access to that toolkit it's as simple as copying and pasting a link from arcade directly into cloud so it's a very simple you know two-step process and from that point on you're all covered okay
[37:56] Oliver Schouest: okay do you have any
[37:58] Adam Zawacki: questions or i don't have any more questions from our side um i mean it's interesting we can we can explore this um like i said uh we kind of have to come up with some use cases figure out i i definitely wouldn't do this until we were fully on board with our new wms otherwise it just seems like Emmit Hood time to bring in our old WMS and then switch it out. But there's some interesting things there. We can dive deeper, I think.
[38:41] Nathan Bass: Emmett, correct me if I'm wrong, but we could also help with that migration in some ways too, right? Whether that's helping get information from one WMS to the other. I'm just saying that we don't necessarily have to wait until that. point but obviously whatever timeline you guys want to work on yeah no I wouldn't
[39:04] Adam Zawacki: I mean I'm sure you guys could help with that but it just to me it seems like something I wouldn't want to tackle just because we have so much other stuff going on getting that off off the ground you know yeah okay
[39:22] Nathan Bass: sounds good well I would still love the Connect next week and see if there's non WMS use cases that we could tackle Is that is that cool with you guys?
[39:35] Adam Zawacki: Yeah, we can do sounds good.
[39:37] Nathan Bass: Sounds good. So we'll we'll send that email over. We'll try to nail For late next week so we can we could talk a little bit more in depth and I'll send over some some more resources for You all take a maybe to send over like
[39:52] Oliver Schouest: I guess popular workflows like stuff that you guys are implementing with that your clients really like that, you know stuff that I guess arcade excels at or if that makes sense because I feel like if we had examples that we could Really think how could you know, how could we adapt this? What's something you know, that type of thing that'll really help with
[40:09] Adam Zawacki: Yeah, I think that's a great call out kind of Put us in the right mindset to see how we could use that switch it up a little bit to make it fit our business
[40:22] Emmit Hood: Cool. Sounds good. Can do.
[40:26] Nathan Bass: Well, thank you guys so much for taking the time. It was great to meet you guys.
[40:32] Adam Zawacki: don't hesitate to reach out yeah thanks guys have a good weekend thank you all right take care bye
